{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba3d99ea-7935-4b21-a18d-5450ef119ed2",
   "metadata": {},
   "source": [
    "# Heuristic User Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c71638-d1ea-4aef-b8f1-bdc5992ef33e",
   "metadata": {},
   "source": [
    "A walkthrough of the heuristic functions I've created using Holiday's stroke error scoring and how to understand them.\n",
    "\n",
    "The goal is to create a function that returns as high a score as possible for any given gene-archetype pairing without sacrificing speed. Aim to:\n",
    "- Reduce calls to the Stylus API (meaning generate less stroke orders to score)\n",
    "- Reduce time complexity (meaning reduce the amount of potential stroke maps to iterate through)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f66628-08c6-4b2b-ad08-0ee841f7fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4e98b-e6a1-4cab-8d25-ef8892051658",
   "metadata": {},
   "source": [
    "Get used to working with NumPy arrays instead of standard Python lists. When building heuristics, avoid iteration (especially nested for loops) as that makes time complexity worse. Instead, try to vectorize where you can. NumPy has plenty of functions to work with arrays that are faster than Python's built-in methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e1ceb6-ab8e-4d1a-866c-12bdfca9e16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24T22:50:03.915338Z [INFO ] Stylus initialized - Stylus 1.5.0 [RELEASE - May 21 2024 14:06:24] (c) 2006-2009 Biologic Institute\n"
     ]
    }
   ],
   "source": [
    "from score_strokes import strokeErrorMatrix\n",
    "from xmlparse import loadGeometryBases, loadRef, getXmlScore, minXml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d10131-b293-4a50-a598-d5b10eee5317",
   "metadata": {},
   "source": [
    "These are functions from Holiday's code that my heuristics are built from. They are the foundation for building heuristics that I used. Make sure to read over her documentation on her repo, which is linked in the README of this repo.\n",
    "\n",
    "When first importing you should see a message that says [INFO ] Stylus initialized - Stylus...\n",
    "This message just means that Stylus is up and running correctly. Make sure that Stylus is configured correctly or else you will encounter errors.\n",
    "\n",
    "**strokeErrorMatrix** is used to generate an n*m matrix of stroke errors where n is the number of archetype strokes and m is the number of gene strokes.\n",
    "- In certain genes, n does not match m despite the gene being a mutation of an archetype with m strokes. These are called marks.\n",
    "- The smaller the stroke error, the closer the gene stroke is to the archetype stroke.\n",
    "- The stroke error measurement is not perfect and can be improved, which I heavily recommend future project members to focus on.\n",
    "\n",
    "**loadGeometryBases** loads the gene data for each file in a specified directory.\n",
    "\n",
    "**loadRef** loads the archetype data for a specific reference character.\n",
    "\n",
    "**minXml** generates the XML data necessary for Stylus to score a gene.\n",
    "\n",
    "**getXmlScore** calls the Stylus API and returns a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1cbb8d-0c19-4fa2-be64-1c262adac9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983d31eb-9969-4c53-88fb-4c2c0c80182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dir = f'{Path.home()}/Stylus_Scoring_Generalization/Reference' # archetype directory\n",
    "data_dir = f'{Path.home()}/Stylus_Scoring_Generalization/NewGenes' # gene directory\n",
    "ref_char = \"4EFB\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf508d-ac81-4451-be25-c87d18b2cd54",
   "metadata": {},
   "source": [
    "Your reference directory (where to find the archetype data) and your gene directory (where to find the gene data). You can find sample genes (keep in mind these sample genes all have six strokes) in Holiday's repo at Genes/sixgenes, I changed the directory for my own purposes.\n",
    "\n",
    "The reference character is the Unicode representation of your archetype that the genes will be scored against (see the Reference folder in Holiday's repo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bdc3ee8-6ea2-469c-9f33-e6912dbdb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_count = 6\n",
    "stroke_map = np.empty(stroke_count, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98fd5b5-1736-4bcd-8ccb-67aef0e8ea6a",
   "metadata": {},
   "source": [
    "Before getting into the actual heuristic algorithms it may be helpful to understand the fundamentals. The goal is to generate a stroke map, but what is a stroke map?\n",
    "\n",
    "A stroke map is an array matching gene strokes to archetype strokes. Stylus isn't able to determine the best match between each gene stroke and each archetype stroke, so we have to do it ourselves. For example, say I'm attempting to match a six stroke gene to a six stroke archetype. Remember that array indices begin from 0. Let's say gene stroke 0 matches up best with archetype stroke 2. The gene stroke becomes the index and the archetype stroke becomes the value in the stroke map array. In this case, stroke_map[0] = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8758c22-7746-4aec-ab87-bb32fc3de2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_map[0] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3375357-f8d8-474a-8f24-9cea6781e546",
   "metadata": {},
   "source": [
    "Continue on and you might end up with something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6998fef-833f-4cb5-80e2-7e727d4f5dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 4 0 3 5]\n"
     ]
    }
   ],
   "source": [
    "# pretend our heuristic generates this stroke map...\n",
    "stroke_map[5] = 5\n",
    "stroke_map[3] = 0\n",
    "stroke_map[1] = 1\n",
    "stroke_map[2] = 4\n",
    "stroke_map[4] = 3\n",
    "\n",
    "print(stroke_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfba37fc-9e5c-43c5-9a8a-0648375f8109",
   "metadata": {},
   "source": [
    "Again, the gene strokes are the indices and the archetype strokes are the values. This can be quite confusing but there's no way around it.\n",
    "\n",
    "In **strokeErrorMatrix**, the rows are the archetype strokes and the columns are the gene strokes. Each row-column coordinate represents the error between that archetype stroke and that gene stroke. So matrix[2][0] represents the error between archetype stroke 2 and gene stroke 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d03f09-6c9b-4504-a37f-c87430ca8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def heuristic_total(strokes, ref, p_strokes, p_ref):\n",
    "    error_maps = strokeErrorMatrix(strokes, ref, p_strokes, p_ref) # Retrieve error matrix\n",
    "    least = 10000 # Since we want the smallest possible total error, the variable should be set to a high number\n",
    "    stroke_map = ()\n",
    "    for priority in permutations(range(len(ref))): # Iterate over every permutation of stroke order\n",
    "        s = np.sum(error_maps[np.arange(len(error_maps)), priority]) # Sum every error in this particular stroke order\n",
    "        if s < least: # Check if the generated sum is smaller than the current sum stored\n",
    "            least = s\n",
    "            stroke_map = priority\n",
    "    return np.argsort(stroke_map) # Swap indices and values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ebb485-f5e8-462d-a70a-06914d31ebd7",
   "metadata": {},
   "source": [
    "As an example, here's one of my heuristic functions. All of my heuristics are located in benchmark.py (which is in this repo). Specifically, this heuristic takes every possible ordering of errors, calculates the sum of the errors, and returns the ordering with the lowest sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe43a853-7dbe-463c-935e-29161b977004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one score 0.2009721093859917\n",
      "And here's the stroke map that obtained this score [1 2 6 5 3 4]\n"
     ]
    }
   ],
   "source": [
    "from compare_genes import getScores\n",
    "\n",
    "heuristic_scores, heuristic_alignments, marks = getScores(heuristic_total, ref_char, data_dir)\n",
    "print(\"Here's one score\", heuristic_scores[0])\n",
    "print(\"And here's the stroke map that obtained this score\", heuristic_alignments[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14977f51-235e-4915-99b6-0d1dd2bbd530",
   "metadata": {},
   "source": [
    "Holiday's API makes it very simple to obtain scores given a certain heuristic algorithm. Any function with the correct call signature (which can be found in her documentation under **getScores**) is compatible with **getScores**.\n",
    "\n",
    "Now you might be wondering, why does the stroke map returned from **getScores** range from 1-6 instead of 0-5? Well, that's simply because Stylus starts with stroke 1 and not stroke 0. **getScores** adds 1 to every value in the stroke map before scoring.\n",
    "\n",
    "But algorithms compatible with **getScores** must return a single stroke order. What if we wanted to score multiple stroke orders and compare them to find the best one?\n",
    "\n",
    "The problem with doing this is that it likely increases the algorithm's time complexity, which is not ideal. But doing so may yield more accurate scores. In order to approach the problem in this manner, we need to understand what **getScores** is really doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bd5319b-5566-4897-8ff8-615fe13518ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied directly from compare_genes.py\n",
    "\n",
    "def getScoresExample(algorithm, ref_char, data_dir): # changed name to avoid conflicts\n",
    "    \"\"\"\n",
    "    Calculates scores for a set of gene characters against a given reference with a heuristic algorithm\n",
    "    Files from the directory specified with gene data are read in a deterministic order (same files = same order)\n",
    "    Input:\n",
    "    algorithm: A function with the below signature. Takes stroke geometry and archetype geometry and scores the stroke against the archetype\n",
    "        Input:\n",
    "        stroke_geometry: List of the strokes from the gene instance\n",
    "        reference_geometry: List of the strokes from the archetype\n",
    "        stroke_fractional_distance: List of fractional distances (a.k.a. progress percentages) for each stroke in the gene instance\n",
    "        reference_fractional_distance: List of fractional distances (a.k.a. progress percentages) for each stroke in the reference\n",
    "    ref_char: UTF-8 name of the archetype in question\n",
    "    data_dir: Directory with the gene files for testing\n",
    "    Output:\n",
    "    heuristic_scores: The scores returned from the given algorithm for each of the genes in the directory\n",
    "    heuristic_alignments: Alignments which the algorithm returned\n",
    "    marks: Whether or not each respective score has a mark, which is an additional stroke which has no counterpart in the archetype\n",
    "    \"\"\"\n",
    "    heuristic_alignments = []\n",
    "    heuristic_scores = []\n",
    "    marks = []\n",
    "    ref_geometry, ref_progress_percentage, output_size = loadRef(ref_char, \"Reference\")\n",
    "    g_data, han_chars, base_data, stroke_sets, stroke_orders, f_names = loadGeometryBases(data_dir, output_size)\n",
    "    for (geometry_length, han_char, bases, stroke_set, stroke_order, f_name) in zip(g_data, han_chars, base_data, stroke_sets, stroke_orders, f_names):\n",
    "        geometry, progress_percentage = geometry_length\n",
    "        heuristic_alignment = np.array(algorithm(geometry, ref_geometry, progress_percentage, ref_progress_percentage))+1\n",
    "        heuristic_alignments.append(heuristic_alignment)\n",
    "        heuristic_xml = minXml(ref_char, bases, stroke_set, heuristic_alignment)\n",
    "        heuristic_score = getXmlScore(heuristic_xml)\n",
    "        heuristic_scores.append(heuristic_score)\n",
    "        marks.append(len(geometry)!=len(ref_geometry))\n",
    "    return heuristic_scores, heuristic_alignments, marks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5c5c3-99fb-4c77-8d25-4c727281cbc0",
   "metadata": {},
   "source": [
    "Understanding **getScores** shouldn't be too difficult of a task. You should be familiar with loadRef, loadGeometryBases, minXml, and getXmlScore from Holiday's documentation (right??). It's just a function that loops over each gene file, calls our heuristic algorithm to generate the stroke map for the gene/archetype pairing, and scores the gene based on our stroke map. We can ignore marks for now.\n",
    "\n",
    "So if we want to score multiple stroke maps, it's simple. We generate XML through **minXml** and call **getXmlScore** for each stroke map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ef97f7d-d893-4b36-834a-10bbe9c4464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's another score 0.2009721093859917\n"
     ]
    }
   ],
   "source": [
    "ref_data = loadRef(ref_char, ref_dir)\n",
    "char_data = loadGeometryBases(data_dir, ref_data[2])\n",
    "\n",
    "def heuristic_small(ref_char, ref_data, char_data):\n",
    "    ref, p_ref, output_size = ref_data\n",
    "    g_data, _, base_data, stroke_sets, _, _ = char_data # We don't really need han_chars, stroke_orders, or f_names right now\n",
    "    heuristic_scores = []\n",
    "    for (geometry_length, bases, stroke_set) in zip(g_data, base_data, stroke_sets):\n",
    "        strokes, p_strokes = geometry_length\n",
    "        error_maps = strokeErrorMatrix(strokes, ref, p_strokes, p_ref)\n",
    "        compare_scores = []\n",
    "        stroke_maps = []\n",
    "        smallerrs = np.min(error_maps, axis=1) # Get the smallest error in every row\n",
    "        smallerr_count = 0\n",
    "        for priority in permutations(range(len(ref))): # Iterate over every permutation of stroke order\n",
    "            c = np.count_nonzero(smallerrs == error_maps[np.arange(len(error_maps)), priority]) # Get the frequency of smallest errors in current stroke map\n",
    "            if c > smallerr_count:\n",
    "                smallerr_count = c\n",
    "                stroke_maps.clear() # Remove the stored stroke maps with the previous frequency\n",
    "                stroke_maps.append(np.argsort(priority))\n",
    "            elif c == smallerr_count: # Potentially multiple stroke maps with the same frequency\n",
    "                stroke_maps.append(np.argsort(priority))\n",
    "        for m in stroke_maps:\n",
    "            heuristic_xml = minXml(ref_char, bases, stroke_set, m+1) # Remember to add 1 to your stroke maps\n",
    "            heuristic_score = getXmlScore(heuristic_xml)\n",
    "            compare_scores.append(heuristic_score)\n",
    "        heuristic_scores.append(max(compare_scores))\n",
    "    return heuristic_scores\n",
    "\n",
    "print(\"Here's another score\", heuristic_small(ref_char, ref_data, char_data)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14b539-0373-4619-9f4c-9a1e891e2149",
   "metadata": {},
   "source": [
    "This is an example of a heuristic that scores multiple stroke maps and returns the heuristic scores for each gene file without using **getScores**. Similar to **heuristic_total**, the heuristic loops over every possible ordering of errors, but this time, it takes a different approach to locating the optimal stroke map. The current heuristic finds the smallest error in each row of the matrix, then counts the number of times these smallest errors appear in the current stroke map. The stroke maps with the greatest number of smallest errors are scored, and the highest scoring stroke map is selected.\n",
    "\n",
    "Next, we'll move on to benchmarking our heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28e80b01-a2db-4046-9797-b200a73f2c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heuristic_total:\t0.5946931977756321 s\n",
      "heuristic_small:\t0.4756078031845391 s\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "total_time = timeit.Timer('getScores(heuristic_total, ref_char, data_dir)', globals=locals()).timeit(number=10)\n",
    "small_time = timeit.Timer('heuristic_small(ref_char, ref_data, char_data)', globals=locals()).timeit(number=10)\n",
    "formatter = len(max([\"heuristic_total\", \"heuristic_small\"], key=len))\n",
    "print(\"{:>{}}:\\t{} s\".format(\"heuristic_total\", formatter, total_time/10))\n",
    "print(\"{:>{}}:\\t{} s\".format(\"heuristic_small\", formatter, small_time/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427ae16-7ae5-4ef4-b143-4d7447550f96",
   "metadata": {},
   "source": [
    "When benchmarking code, using timeit yields more accurate results than simply using time.time() for multiple reasons. You can run the function multiple times by changing the number parameter in the Timer.timeit() method. \n",
    "\n",
    "**heuristic_small** looks significantly faster than **heuristic_total**, but to make it more fair, we'll move the calls to **loadRef** and **loadGeometryBases** inside the **heuristic_small** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db6481f9-c4a6-486b-b89c-c4cc2b28010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        heuristic_total:\t0.5981374118011444 s\n",
      "        heuristic_small:\t0.5815679595340043 s\n",
      "                 greedy:\t0.3878414945676923 s\n"
     ]
    }
   ],
   "source": [
    "from score_strokes import alignStrokes\n",
    "\n",
    "def heuristic_small_again(ref_char, ref_dir, data_dir):\n",
    "    ref, p_ref, output_size = loadRef(ref_char, ref_dir)\n",
    "    g_data, _, base_data, stroke_sets, _, _ = loadGeometryBases(data_dir, output_size) # We don't really need han_chars, stroke_orders, or f_names right now\n",
    "    heuristic_scores = []\n",
    "    for (geometry_length, bases, stroke_set) in zip(g_data, base_data, stroke_sets):\n",
    "        strokes, p_strokes = geometry_length\n",
    "        error_maps = strokeErrorMatrix(strokes, ref, p_strokes, p_ref)\n",
    "        compare_scores = []\n",
    "        stroke_maps = []\n",
    "        smallerrs = np.min(error_maps, axis=1) # Get the smallest error in every row\n",
    "        smallerr_count = 0\n",
    "        for priority in permutations(range(len(ref))): # Iterate over every permutation of stroke order\n",
    "            c = np.count_nonzero(smallerrs == error_maps[np.arange(len(error_maps)), priority])\n",
    "            if c > smallerr_count:\n",
    "                smallerr_count = c\n",
    "                stroke_maps.clear()\n",
    "                stroke_maps.append(np.argsort(priority))\n",
    "            elif c == smallerr_count:\n",
    "                stroke_maps.append(np.argsort(priority))\n",
    "        for m in stroke_maps:\n",
    "            heuristic_xml = minXml(ref_char, bases, stroke_set, m+1) # Remember to add 1 to your stroke maps\n",
    "            heuristic_score = getXmlScore(heuristic_xml)\n",
    "            compare_scores.append(heuristic_score)\n",
    "        heuristic_scores.append(max(compare_scores))\n",
    "    return heuristic_scores\n",
    "\n",
    "total_time = timeit.Timer('getScores(heuristic_total, ref_char, data_dir)', globals=locals()).timeit(number=10)\n",
    "small_time = timeit.Timer('heuristic_small_again(ref_char, ref_dir, data_dir)', globals=locals()).timeit(number=10)\n",
    "greedy_time = timeit.Timer('getScores(alignStrokes, ref_char, data_dir)', globals=locals()).timeit(number=10) # added on Holiday's greedy algorithm as well\n",
    "formatter = len(max([\"greedy, heuristic_total\", \"heuristic_small\"], key=len))\n",
    "print(\"{:>{}}:\\t{} s\".format(\"heuristic_total\", formatter, total_time/10))\n",
    "print(\"{:>{}}:\\t{} s\".format(\"heuristic_small\", formatter, small_time/10))\n",
    "print(\"{:>{}}:\\t{} s\".format(\"greedy\", formatter, greedy_time/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a2276-57eb-4fa0-9f79-0b1ad6f8f7ca",
   "metadata": {},
   "source": [
    "And that's probably as close as we can get to accurate. But in my personal experience different reference characters and gene files result in different speeds for different heuristics. In real time, 0.6ish seconds doesn't seem bad at all for 62 genes. It's around 0.2 seconds slower than Holiday's original greedy algorithm but much faster than the exhaustive, so it's all good, right?\n",
    "\n",
    "It's better to think about it this way: my heuristics take a little under double the amount of time as Holiday's greedy algorithm. As the number of genes to be scored increases, the amount of time taken by my heuristics will grow at a faster rate than Holiday's. Which is why increasing the time complexity to achieve more accurate results isn't exactly the best solution, we want to keep things at O(n) or better if possible. There's always improvement to be made!\n",
    "\n",
    "I've created a script that benchmarks all my heuristic functions at benchmark.py. Adding your own heuristics to benchmark.py isn't hard, just requires a bit of tweaking. Or if you prefer, you can write your own benchmarking program; mine is pretty messy and could definitely be improved on.\n",
    "\n",
    "One last thing; checking the accuracy of your heuristic. We want our heuristic to generate a stroke map that results in as high of a score as possible, or as close to the exhaustive score as possible. It is quite difficult to get scores that match the exhaustive scores perfectly without sacrificing speed, so we just want to get as close as we can. Here's a comparison of the two heuristics we've been using and Holiday's original greedy algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "964f63a6-3a3a-47c1-a18a-bf632c7d93dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heuristic_total achieved the highest score 32 times.\n",
      "heuristic_small achieved the highest score 56 times.\n",
      "greedy achieved the highest score 40 times.\n"
     ]
    }
   ],
   "source": [
    "total_scores, _, _ = getScores(heuristic_total, ref_char, data_dir)\n",
    "small_scores = heuristic_small(ref_char, ref_data, char_data)\n",
    "greedy_scores, _, _ = getScores(alignStrokes, ref_char, data_dir)\n",
    "\n",
    "total_wins = 0\n",
    "small_wins = 0\n",
    "greedy_wins = 0\n",
    "\n",
    "for (total_score, small_score, greedy_score) in zip(total_scores, small_scores, greedy_scores):\n",
    "    best_score = max(total_score, small_score, greedy_score)\n",
    "    if best_score == total_score:\n",
    "        total_wins += 1\n",
    "    if best_score == small_score:\n",
    "        small_wins += 1\n",
    "    if best_score == greedy_score:\n",
    "        greedy_wins += 1\n",
    "\n",
    "print(\"heuristic_total achieved the highest score\", total_wins, \"times.\")\n",
    "print(\"heuristic_small achieved the highest score\", small_wins, \"times.\")\n",
    "print(\"greedy achieved the highest score\", greedy_wins, \"times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7caae0-b2b7-4973-a211-ac694dbae6f2",
   "metadata": {},
   "source": [
    "Good luck building your heuristics! I hope this guide helped.\n",
    "\n",
    "*Daniel Rhee*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
