{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdeaff59-baae-43fd-b0e2-3c66864d1547",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from math import factorial\n",
    "from pathlib import Path\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "\n",
    "from compare_genes import getScores\n",
    "from xmlparse import loadGeometryBases, getXmlScore, minXml\n",
    "from score_strokes import alignStrokes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b1c7e8-2656-444e-8ac0-ed0f046528f3",
   "metadata": {},
   "source": [
    "## Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14054b6-1e61-4ee2-b0d2-c9c87ae26db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited from exhaustive.py\n",
    "def computeExhaustive(ref_char, f_read, data_dir, exhaust_dir = \"Exhaustive\", prog_interval = 100, save = True, xml_dir = \"GenXml/Exhaustive\", save_file = \"\"):\n",
    "    ref_g, ref_l, output_size = loadRef(ref_char, ref_dir)\n",
    "    g_data, _, base_data, stroke_sets, _, f_names = loadGeometryBases(data_dir, output_size, f_read = f_read)\n",
    "    n_strokes = len(ref_g)\n",
    "    for i in range(len(g_data)):\n",
    "        #print(f\"Generating exhaustive scores for sample {f_read[i]}\")\n",
    "        bases = base_data[i]\n",
    "        stroke_set = stroke_sets[i]\n",
    "        exhaustive_alignments = permutations(range(1, n_strokes+1))\n",
    "        exhaustive_scores = np.zeros(factorial(n_strokes))\n",
    "        for j, p in enumerate(exhaustive_alignments):\n",
    "            p_xml = minXml(ref_char, bases, stroke_set, p)\n",
    "            exhaustive_scores[j] = getXmlScore(p_xml, f\"{xml_dir}/{i}_{j}_{f_read[i]}\", f\"{xml_dir}/{i}_{j}_min_{f_read[i]}\")\n",
    "            #exhaustive_scores[j] = getXmlScore(p_xml, False, False)\n",
    "            #if j%prog_interval == 0:\n",
    "            #    print(f\"Scoring permutation {j} of {len(exhaustive_scores)}\")\n",
    "        if save:\n",
    "            if save_file == \"\":\n",
    "                f_name_cleaned = f_read[i].replace(\"/\", \"_\")\n",
    "                f\"{exhaust_dir}/exhaust_{ref_char}_{f_name_cleaned}.npy\"\n",
    "            print(f\"Wrote exhaustive scores to {save_file}\")\n",
    "            np.save(save_file, exhaustive_scores)\n",
    "        yield exhaustive_scores\n",
    "\n",
    "# Edited from exhaustive.py\n",
    "def exhaustScore(ref_char, f_name, data_dir, exhaust_dir = \"Exhaustive\", force_refresh = False, save = True, file_prefix = \"\"):\n",
    "    f_name_cleaned = f_name.replace(\"/\", \"_\")\n",
    "    exhaust_name = f\"{exhaust_dir}/exhaust_{file_prefix}{ref_char}_{f_name_cleaned}.npy\"\n",
    "    exhaust_maxes = []\n",
    "    if not os.path.isfile(exhaust_name) or force_refresh:\n",
    "        for e in computeExhaustive(ref_char, [f_name], data_dir, save = save, xml_dir = f'{str(Path.home())}/Stylus_Scoring_Generalization/GenXml/Exhaustive', save_file = exhaust_name):\n",
    "            exhaust_maxes.append(e.max())\n",
    "    else:\n",
    "        exhaust_maxes = readExhaustive(ref_char, f_name, exhaust_dir, exhaust_name)\n",
    "    return np.max(exhaust_maxes)\n",
    "\n",
    "# Edited from xmlparse.py\n",
    "def loadRef(han_char, ref_dir = \"Reference\"):\n",
    "    stroke_list = []\n",
    "    frac_dists = []\n",
    "    ref_path = f\"{ref_dir}/{han_char}.han\"\n",
    "    ref_xml = open(ref_path, \"r\").read()\n",
    "    root = xmltodict.parse(ref_xml)\n",
    "    bounds = root[\"hanDefinition\"][\"bounds\"]\n",
    "    x_min, y_min, x_max, y_max = (float(bounds[\"@left\"]), float(bounds[\"@bottom\"]), float(bounds[\"@right\"]), float(bounds[\"@top\"]))\n",
    "    scale = (int(x_max-x_min), int(y_max-y_min))\n",
    "    strokes = root[\"hanDefinition\"][\"strokes\"][\"stroke\"]\n",
    "    for stroke in strokes:\n",
    "        points = stroke[\"points\"][\"forward\"]\n",
    "        point_arr = []\n",
    "        frac_arr = []\n",
    "        for point in points[\"pointDistance\"]:\n",
    "            point_arr.append((float(point[\"@x\"])-x_min,\n",
    "                              float(point[\"@y\"])-y_min))\n",
    "            frac_arr.append(float(point[\"@fractionalDistance\"]))\n",
    "        stroke_list.append(np.array(point_arr))\n",
    "        frac_dists.append(np.array(frac_arr))\n",
    "    return stroke_list, frac_dists, scale\n",
    "\n",
    "# Obtaining scores through heuristic algorithm\n",
    "def heuristicScores(algo, ref_char, ref_data, char_data):\n",
    "    heuristic_alignments = []\n",
    "    heuristic_scores = []\n",
    "    ref_geometry, ref_progress_percentage, output_size = ref_data\n",
    "    g_data, _, base_data, stroke_sets, _, f_names = char_data\n",
    "    for (geometry_length, bases, stroke_set, _, f_name) in zip(g_data, base_data, stroke_sets, _, f_names):\n",
    "        geometry, progress_percentage = geometry_length\n",
    "        heuristic_alignment = np.array(algo(geometry, ref_geometry, progress_percentage, ref_progress_percentage))+1\n",
    "        heuristic_alignments.append(heuristic_alignment)\n",
    "        heuristic_xml = minXml(ref_char, bases, stroke_set, heuristic_alignment)\n",
    "        heuristic_score = getXmlScore(heuristic_xml)\n",
    "        heuristic_scores.append(heuristic_score)\n",
    "    return heuristic_scores, heuristic_alignments\n",
    "\n",
    "# Obtaining scores through exhaustive search\n",
    "def exhaustiveScores(ref_char, data_dir, char_data):\n",
    "    g_data, han_chars, base_data, _, _, f_names = char_data\n",
    "    exhaustive_scores = []\n",
    "    for (gl, han_char, bases, f_name) in zip(g_data, han_chars, base_data, f_names):\n",
    "        g, l = gl\n",
    "        original_score = exhaustScore(ref_char, f_name, data_dir, force_refresh=True, save=False)\n",
    "        exhaustive_scores.append(original_score)\n",
    "    return exhaustive_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be21636b-d4e6-418b-b620-6210c0f0570c",
   "metadata": {},
   "source": [
    "## Gene/Archetype Combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a609e68-93ab-410c-8aaf-b6c1c14d5403",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_dir = f'{str(Path.home())}/Stylus_Scoring_Generalization/NewRef' # archetype directory\n",
    "data_dir = f'{str(Path.home())}/Stylus_Scoring_Generalization/NewGenes' # gene directory\n",
    "\n",
    "# Retrieve all reference characters\n",
    "ref_chars = []\n",
    "for _, _, f_names in os.walk(ref_dir):\n",
    "    ref_chars.extend(f.split(\".\")[0] for f in f_names)\n",
    "ref_chars = list(filter(None, ref_chars))\n",
    "\n",
    "# Retrieve scores for every gene/archetype combo and write data to CSV\n",
    "cf = open('test.csv', 'w', newline='')\n",
    "writer = csv.writer(cf)\n",
    "writer.writerow([\"GeneId\", \"ArchetypeId\", \"ExhaustiveScore\", \"HeuristicScore\", \"GeneMap\", \"HeuristicMap\"])\n",
    "gene_names = os.listdir(data_dir)\n",
    "gene_names.sort()\n",
    "for i, g in enumerate(gene_names):\n",
    "    gene_names[i] = g.split(\".gene\")[0]\n",
    "for ref_char in ref_chars:\n",
    "    ref_data = loadRef(ref_char, ref_dir)\n",
    "    char_data = loadGeometryBases(data_dir, ref_data[2])\n",
    "    for stroke in char_data[0][0]:\n",
    "        if len(ref_data[0]) != len(stroke):\n",
    "            break\n",
    "    else:\n",
    "        stroke_orders = char_data[4]\n",
    "        heuristic_scores, heuristic_alignments = heuristicScores(alignStrokes, ref_char, ref_data, char_data)\n",
    "        exhaustive_scores = exhaustiveScores(ref_char, data_dir, char_data)\n",
    "        for (gene_name, heuristic_score, exhaustive_score, stroke_order, heuristic_alignment) in zip(gene_names, heuristic_scores, exhaustive_scores, stroke_orders, heuristic_alignments):\n",
    "            writer.writerow([gene_name, ref_char, exhaustive_score, heuristic_score, stroke_order, heuristic_alignment])\n",
    "cf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
