{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdeaff59-baae-43fd-b0e2-3c66864d1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from compare_genes import getScores\n",
    "from xmlparse import loadRef, loadGeometryBases, getXmlScore, minXml\n",
    "from score_strokes import alignStrokes\n",
    "from exhaustive import exhaustScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b1c7e8-2656-444e-8ac0-ed0f046528f3",
   "metadata": {},
   "source": [
    "## Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14054b6-1e61-4ee2-b0d2-c9c87ae26db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristicScores(algo, ref_char, ref_dir, data_dir):\n",
    "    heuristic_alignments = []\n",
    "    heuristic_scores = []\n",
    "    ref_geometry, ref_progress_percentage, output_size = loadRef(ref_char, ref_dir)\n",
    "    g_data, _, base_data, stroke_sets, _, f_names = loadGeometryBases(data_dir, output_size)\n",
    "    for (geometry_length, bases, stroke_set, _, f_name) in zip(g_data, base_data, stroke_sets, _, f_names):\n",
    "        geometry, progress_percentage = geometry_length\n",
    "        heuristic_alignment = np.array(algo(geometry, ref_geometry, progress_percentage, ref_progress_percentage))+1\n",
    "        heuristic_alignments.append(heuristic_alignment)\n",
    "        heuristic_xml = minXml(ref_char, bases, stroke_set, heuristic_alignment)\n",
    "        heuristic_score = getXmlScore(heuristic_xml)\n",
    "        heuristic_scores.append(heuristic_score)\n",
    "    return heuristic_scores, heuristic_alignments\n",
    "\n",
    "# Obtaining scores through exhaustive search\n",
    "def exhaustiveScores(ref_char, data_dir, char_data):\n",
    "    g_data, han_chars, base_data, _, _, f_names = char_data\n",
    "    exhaustive_scores = []\n",
    "    for (gl, han_char, bases, f_name) in zip(g_data, han_chars, base_data, f_names):\n",
    "        g, l = gl\n",
    "        original_score = exhaustScore(ref_char, f_name, data_dir, force_refresh=True, save=False)\n",
    "        exhaustive_scores.append(original_score)\n",
    "    return exhaustive_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be21636b-d4e6-418b-b620-6210c0f0570c",
   "metadata": {},
   "source": [
    "## Gene/Archetype Combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a609e68-93ab-410c-8aaf-b6c1c14d5403",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m char_data \u001b[38;5;241m=\u001b[39m loadGeometryBases(data_dir, output_size)\n\u001b[1;32m     22\u001b[0m stroke_orders \u001b[38;5;241m=\u001b[39m char_data[\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m heuristic_scores, heuristic_alignments \u001b[38;5;241m=\u001b[39m heuristicScores(alignStrokes, ref_char, ref_dir, data_dir)\n\u001b[1;32m     24\u001b[0m exhaustive_scores \u001b[38;5;241m=\u001b[39m exhaustiveScores(ref_char, data_dir, char_data)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (gene_name, heuristic_score, exhaustive_score, stroke_order, heuristic_alignment) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(gene_names, heuristic_scores, exhaustive_scores, stroke_orders, heuristic_alignments):\n",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m, in \u001b[0;36mheuristicScores\u001b[0;34m(algo, ref_char, ref_dir, data_dir)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (geometry_length, bases, stroke_set, _, f_name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(g_data, base_data, stroke_sets, _, f_names):\n\u001b[1;32m      7\u001b[0m     geometry, progress_percentage \u001b[38;5;241m=\u001b[39m geometry_length\n\u001b[0;32m----> 8\u001b[0m     heuristic_alignment \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(algo(geometry, ref_geometry, progress_percentage, ref_progress_percentage))\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m     heuristic_alignments\u001b[38;5;241m.\u001b[39mappend(heuristic_alignment)\n\u001b[1;32m     10\u001b[0m     heuristic_xml \u001b[38;5;241m=\u001b[39m minXml(ref_char, bases, stroke_set, heuristic_alignment)\n",
      "File \u001b[0;32m~/stylus-misc/score_strokes.py:49\u001b[0m, in \u001b[0;36malignStrokes\u001b[0;34m(strokes, ref, p_strokes, p_ref)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(stroke_map[smallerror]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# change small error so that we do not repeat over indexes that are already taken\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# just keeps repeating until we land on an index that doesn't already have a value in its place\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     error_maps[largestref][smallerror] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m---> 49\u001b[0m     smallerror \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(error_maps[largestref])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#print(largestref, smallerror)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m stroke_map[smallerror] \u001b[38;5;241m=\u001b[39m largestref \u001b[38;5;66;03m# set the index in the stroke_map to the reference stroke we designated\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1232\u001b[0m, in \u001b[0;36m_argmin_dispatcher\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m-> 1232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_argmin_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argmin_dispatcher)\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margmin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ref_dir = f'{str(Path.home())}/Stylus_Scoring_Generalization/Reference' # archetype directory\n",
    "data_dir = f'{str(Path.home())}/Stylus_Scoring_Generalization/NewGenes' # gene directory\n",
    "\n",
    "# Retrieve all reference characters\n",
    "ref_chars = []\n",
    "dirs = [f.path for f in os.scandir(ref_dir) if f.is_dir()]\n",
    "for d in dirs:\n",
    "    ref_chars.extend(f.split(\".\")[0] for f in os.listdir(d))\n",
    "ref_chars = list(filter(None, ref_chars))\n",
    "\n",
    "# Retrieve scores for every gene/archetype combo\n",
    "with open('test.csv', 'w', newline='') as cf:\n",
    "    writer = csv.writer(cf)\n",
    "    writer.writerow([\"GeneId\", \"ArchetypeId\", \"ExhaustiveScore\", \"HeuristicScore\", \"GeneMap\", \"HeuristicMap\"])\n",
    "gene_names = os.listdir(data_dir)\n",
    "gene_names.sort()\n",
    "for i, g in enumerate(gene_names):\n",
    "    gene_names[i] = g.split(\".gene\")[0]\n",
    "for ref_char in ref_chars:\n",
    "    _, _, output_size = loadRef(ref_char, ref_dir)\n",
    "    char_data = loadGeometryBases(data_dir, output_size)\n",
    "    stroke_orders = char_data[4]\n",
    "    heuristic_scores, heuristic_alignments = heuristicScores(alignStrokes, ref_char, ref_dir, data_dir)\n",
    "    exhaustive_scores = exhaustiveScores(ref_char, data_dir, char_data)\n",
    "    for (gene_name, heuristic_score, exhaustive_score, stroke_order, heuristic_alignment) in zip(gene_names, heuristic_scores, exhaustive_scores, stroke_orders, heuristic_alignments):\n",
    "        writer.writerow([gene_name, ref_char, exhaustive_score, heuristic_score, stroke_order, heuristic_alignment])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb595e3-9003-4b7c-91d5-e78d7f23ea39",
   "metadata": {},
   "source": [
    "## Writing to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a851292-f92f-41ae-8382-0165d8d2ce01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
