{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2ac1fd40-cfc4-4514-8cee-eff36c6a74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from score_strokes import strokeErrorMatrix\n",
    "from xmlparse import getXmlScore, loadGeometryBases, loadRef, minXml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b51994b-aeb4-4c0a-8ebd-0334c82740fa",
   "metadata": {},
   "source": [
    "## Dynamic Programming Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "53e0243a-16ef-4992-a40a-4bfbb1a269a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05T22:26:49.910876Z [INFO ] Loaded genome  containing 1 genes - trial set to 0\n",
      "2024-06-05T22:26:49.910945Z [INFO ] TRIAL 0: Fitness is 0.001342939948137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0001031825318209632]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Currently the function is broken, as it does not return scores correctly with multiple gene files in the directory. Can still be tested for one though.\n",
    "Implementation and design of a dynamic programming algorithm are probably incorrect as well, requires heavy testing and more learning on my part.\n",
    "At the moment the algorithm is incompatible with Holiday's API because it requires scoring multiple stroke orders (not O(n)).\n",
    "\"\"\"\n",
    "\n",
    "# Testing a dynamic programming algorithm\n",
    "def dynamic(ref_char, ref_data, char_data):\n",
    "    ref, p_ref, _ = ref_data\n",
    "    g_data, _, base_data, stroke_sets, _, f_names = char_data\n",
    "    stroke_priority = permutations(range(0, len(ref)))\n",
    "    heuristic_scores = []\n",
    "    for (geometry_length, bases, stroke_set, f_name) in zip(g_data, base_data, stroke_sets, f_names):\n",
    "        stroke_maps = []\n",
    "        strokes, p_strokes = geometry_length\n",
    "        error_maps = strokeErrorMatrix(strokes, ref, p_strokes, p_ref)\n",
    "        # Find candidate stroke orders\n",
    "        for priority in stroke_priority:\n",
    "            stroke_map = np.full(len(strokes), -1)\n",
    "            for i in priority:\n",
    "                smallerror = np.argmin(error_maps[i]) # retrieve index of smallest error for current archetype stroke\n",
    "                while(stroke_map[smallerror]!=-1):\n",
    "                    # change small error so that we do not repeat over indexes that are already taken\n",
    "                    # just keeps repeating until we land on an index that doesn't already have a value in its place\n",
    "                    error_maps[i][smallerror] = 10000\n",
    "                    smallerror = np.argmin(error_maps[i])\n",
    "                stroke_map[smallerror] = i\n",
    "            if not any(np.array_equal(stroke_map, m) for m in stroke_maps):\n",
    "                stroke_maps.append(stroke_map)\n",
    "        # Retrieve scores for each candidate stroke order\n",
    "        for s in stroke_maps:\n",
    "            heuristic_xml = minXml(ref_char, bases, stroke_set, np.array(s)+1)\n",
    "            heuristic_score = getXmlScore(heuristic_xml)\n",
    "            heuristic_scores.append(heuristic_score)\n",
    "    return heuristic_scores\n",
    "\n",
    "ref_dir = f'{str(Path.home())}/Stylus_Scoring_Generalization/Reference' # archetype directory\n",
    "data_dir = f'{str(Path.home())}/Stylus_Scoring_Generalization/NewGenes' # gene directory\n",
    "ref_char = \"6709\"\n",
    "\n",
    "ref_data = loadRef(ref_char, ref_dir)\n",
    "char_data = loadGeometryBases(data_dir, ref_data[2])\n",
    "\n",
    "dynamic(ref_char, ref_data, char_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34ea04-876c-49d4-b062-f942ace1e9df",
   "metadata": {},
   "source": [
    "## Heuristic Comparison Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6cd13462-ab60-4b7e-a59b-8b5a5c1e3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to compare two heuristic algorithms' accuracy and performance.\n",
    "\"\"\"\n",
    "def compareHeuristic(algo1, algo2):\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
