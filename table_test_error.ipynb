{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c0f6932-c2f8-4eb4-90a4-99fe2386b702",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'xmlToDict' from 'xmlparse' (/home/emmaw11/Stylus_Scoring_Generalization/xmlparse.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcompare_genes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getScores\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxmlparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loadRef, loadGeometryBases, getXmlScore, minXml, xmlToDict\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscore_strokes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alignStrokes\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexhaustive\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m computeExhaustive, exhaustScore, exhaustScoreAlignment\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'xmlToDict' from 'xmlparse' (/home/emmaw11/Stylus_Scoring_Generalization/xmlparse.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from compare_genes import getScores\n",
    "from xmlparse import loadRef, loadGeometryBases, getXmlScore, minXml, xmlToDict\n",
    "from score_strokes import alignStrokes\n",
    "from exhaustive import computeExhaustive, exhaustScore, exhaustScoreAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b629f-d494-4ed1-a3cd-6b704d4a721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRef2(han_char, ref_dir = \"Reference\"):\n",
    "    \"\"\"\n",
    "    Load the data for an archetype character given the UTF-8 name of the character\n",
    "    Input:\n",
    "    han_char: String containing the UTF-8 name of the character\n",
    "    ref_dir: Directory containing the XML archetype files\n",
    "    Output:\n",
    "    stroke_list: List of strokes from the archetype\n",
    "    frac_dist: Fractional distance of the endpoints of each of the strokes\n",
    "    scale: (x_min, y_min, x_max, y_max) minimum and maximum bounds on archetype strokes\n",
    "    \"\"\"\n",
    "    stroke_list = []\n",
    "    frac_dists = []\n",
    "    #this line is the one that I changed, I removed the {han_char[0]}000 from it\n",
    "    ref_path = f\"{ref_dir}/{han_char}.han\"\n",
    "    ref_xml = open(ref_path, \"r\").read()\n",
    "    root = xmltodict.parse(ref_xml)\n",
    "    bounds = root[\"hanDefinition\"][\"bounds\"]\n",
    "    x_min, y_min, x_max, y_max = (float(bounds[\"@left\"]), float(bounds[\"@bottom\"]), float(bounds[\"@right\"]), float(bounds[\"@top\"]))\n",
    "    scale = (int(x_max-x_min), int(y_max-y_min))\n",
    "    strokes = root[\"hanDefinition\"][\"strokes\"][\"stroke\"]\n",
    "    for stroke in strokes:\n",
    "        points = stroke[\"points\"][\"forward\"]\n",
    "        point_arr = []\n",
    "        frac_arr = []\n",
    "        for point in points[\"pointDistance\"]:\n",
    "            point_arr.append((float(point[\"@x\"])-x_min,\n",
    "                              float(point[\"@y\"])-y_min))\n",
    "            frac_arr.append(float(point[\"@fractionalDistance\"]))\n",
    "        stroke_list.append(np.array(point_arr))\n",
    "        frac_dists.append(np.array(frac_arr))\n",
    "    return stroke_list, frac_dists, scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe2079-2815-4401-9fb5-0d7019ae8b87",
   "metadata": {},
   "source": [
    "## Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c298f2-495a-46fd-96bd-c8c2f6f32384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining scores through heuristic algorithm without getScores\n",
    "def heuristicScores(algo, ref_char, char_data):\n",
    "    ref_g, ref_l, output_size = loadRef2(ref_char, \"Reference/6-stroke_characters\")\n",
    "    g_data, _, base_data, stroke_sets, _, f_names = char_data\n",
    "    heuristic_scores = []\n",
    "    for (gl, bases, stroke_set, f_name) in zip(g_data, base_data, stroke_sets, f_names):\n",
    "        g, l = gl\n",
    "        heuristic_alignment = np.array(algo(g, ref_g, l, ref_l))+1\n",
    "        heuristic_xml = minXml(ref_char, bases, stroke_set, heuristic_alignment)\n",
    "        print(f_name)\n",
    "        print(heuristic_xml)\n",
    "        heuristic_score = getXmlScore(heuristic_xml)\n",
    "        heuristic_scores.append(heuristic_score)\n",
    "    return heuristic_scores\n",
    "\n",
    "# Obtaining scores through heuristic algorithm with getScores\n",
    "def heuristicScoresShort(algo, ref_char, data_dir):\n",
    "    heuristic_scores, _, marks = getScores(algo, ref_char, data_dir)\n",
    "    return heuristic_scores, marks\n",
    "#the below function doesn't work properly because scores doesn't have the same number of elements as exhaustive_scores. Anisa has a more-working\n",
    "#version of this code, for code that actually checks multiple archetypes\n",
    "#However, it's supposed to use heuristicScores to generate scores with all of the archetypes in ref_dir, then find the greatest one for that character\n",
    "#and return it\n",
    "def heuristicScoresWrap(algo, ref_dir, char_data):\n",
    "    max_score = -1\n",
    "    ref_directs = os.listdir(f\"{ref_dir}\")\n",
    "    ref_directs.sort()\n",
    "    for ref_direct in ref_directs:\n",
    "        ref_list = os.listdir(f\"{ref_dir}/{ref_direct}\")\n",
    "        ref_list.sort()\n",
    "        \n",
    "        for ref_char in ref_list:\n",
    "            print(ref_char)\n",
    "            ref_charShort = ref_char[:4:]\n",
    "            print(ref_charShort)\n",
    "            score = heuristicScores(algo, ref_charShort, char_data)\n",
    "            scores = []\n",
    "            for i in score:\n",
    "                if (i > max_score):\n",
    "                    max_score = i\n",
    "            scores.append(max_score)\n",
    "    return scores\n",
    "    \n",
    "# Obtaining scores through exhaustive search\n",
    "def exhaustiveScores(ref_char, char_data, data_dir):\n",
    "    ref_g, ref_l, output_size = loadRef2(ref_char, \"Reference/6-stroke_characters\")\n",
    "    g_data, han_chars, base_data, _, _, f_names = char_data\n",
    "    exhaustive_scores = []\n",
    "    for (gl, han_char, bases, f_name) in zip(g_data, han_chars, base_data, f_names):\n",
    "        g, l = gl\n",
    "        original_score = exhaustScore(ref_char, f_name, data_dir, force_refresh=True, save=False)\n",
    "        exhaustive_scores.append(original_score)\n",
    "    return exhaustive_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf7e9d-44e0-4adb-99cc-94b240d5b447",
   "metadata": {},
   "source": [
    "## Loading genes from a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2772e246-66d1-4a92-be13-5e67369c72f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Genes/sixgenes/test\"\n",
    "\n",
    "han_char = \"56E0\"\n",
    "ref_g, ref_l, output_size = loadRef2(han_char, \"Reference/6-stroke_characters\")\n",
    "char_data = loadGeometryBases(data_dir, output_size)\n",
    "f_names = []\n",
    "marks = []\n",
    "f_names = os.listdir(data_dir)\n",
    "f_names.sort()\n",
    "heuristic_scores = heuristicScores(alignStrokes, han_char, char_data)\n",
    "#heuristic_scores = heuristicScoresWrap(alignStrokes, \"Reference/6-stroke characters\", char_data)\n",
    "\n",
    "#heuristic_scores, marks = heuristicScoresShort(alignStrokes, han_char, data_dir)\n",
    "exhaustive_scores = exhaustiveScores(han_char, char_data, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af13412-466c-4cf4-8200-c7bb6492649a",
   "metadata": {},
   "source": [
    "## Generating a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aacabb-c995-4e24-8aa7-0e0ee5c63f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_dir = \"GenXml\"\n",
    "#gene_names = [f_name.split(\".\")[0] for (i, f_name) in enumerate(f_names)]\n",
    "gene_names = f_names\n",
    "frame = {}\n",
    "if marks != []:\n",
    "    frame = {\"Genes\": gene_names, \"Heuristic Scores\": heuristic_scores, \"Exhaustive Scores\": exhaustive_scores, \"Mark\": marks}\n",
    "else:\n",
    "    frame = {\"Genes\": gene_names, \"Heuristic Scores\": heuristic_scores, \"Exhaustive Scores\": exhaustive_scores}\n",
    "table = pd.DataFrame(frame)\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
