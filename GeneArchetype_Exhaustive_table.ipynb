{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c0f6932-c2f8-4eb4-90a4-99fe2386b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from compare_genes import getScores\n",
    "from xmlparse import loadRef, loadRef2, loadGeometryBases, getXmlScore, minXml\n",
    "from score_strokes import alignStrokes\n",
    "from exhaustive import computeExhaustive, exhaustScore, exhaustScoreAlignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe2079-2815-4401-9fb5-0d7019ae8b87",
   "metadata": {},
   "source": [
    "## Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c298f2-495a-46fd-96bd-c8c2f6f32384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining scores through heuristic algorithm without getScores\n",
    "def heuristicScores(algo, ref_char, char_data):\n",
    "    ref_g, ref_l, output_size = loadRef2(ref_char, \"Reference/7-stroke_characters\")\n",
    "    g_data, _, base_data, stroke_sets, _, f_names = char_data\n",
    "    heuristic_scores = []\n",
    "    for (gl, bases, stroke_set, f_name) in zip(g_data, base_data, stroke_sets, f_names):\n",
    "        g, l = gl\n",
    "        heuristic_alignment = np.array(algo(g, ref_g, l, ref_l))+1\n",
    "        heuristic_xml = minXml(ref_char, bases, stroke_set, heuristic_alignment)\n",
    "        heuristic_score = getXmlScore(heuristic_xml)\n",
    "        heuristic_scores.append(heuristic_score)\n",
    "    return heuristic_scores\n",
    "\n",
    "# Obtaining scores through heuristic algorithm with getScores\n",
    "def heuristicScoresShort(algo, ref_char, data_dir):\n",
    "    heuristic_scores, _, marks = getScores(algo, ref_char, data_dir)\n",
    "    return heuristic_scores, marks\n",
    "#the below function doesn't work properly because scores doesn't have the same number of elements as exhaustive_scores. Anisa has a more-working\n",
    "#version of this code, for code that actually checks multiple archetypes\n",
    "#However, it's supposed to use heuristicScores to generate scores with all of the archetypes in ref_dir, then find the greatest one for that character\n",
    "#and return it\n",
    "def heuristicScoresWrap(algo, ref_dir, char_data):\n",
    "    max_score = -1\n",
    "    ref_directs = os.listdir(f\"{ref_dir}\")\n",
    "    ref_directs.sort()\n",
    "    for ref_direct in ref_directs:\n",
    "        ref_list = os.listdir(f\"{ref_dir}/{ref_direct}\")\n",
    "        ref_list.sort()\n",
    "        \n",
    "        for ref_char in ref_list:\n",
    "            print(ref_char)\n",
    "            ref_charShort = ref_char[:4:]\n",
    "            print(ref_charShort)\n",
    "            score = heuristicScores(algo, ref_charShort, char_data)\n",
    "            scores = []\n",
    "            for i in score:\n",
    "                if (i > max_score):\n",
    "                    max_score = i\n",
    "            scores.append(max_score)\n",
    "    return scores\n",
    "    \n",
    "# Obtaining scores through exhaustive search\n",
    "def exhaustiveScores(ref_char, char_data, data_dir):\n",
    "    ref_g, ref_l, output_size = loadRef2(ref_char, \"Reference/7-stroke_characters\")\n",
    "    g_data, han_chars, base_data, _, _, f_names = char_data\n",
    "    exhaustive_scores = []\n",
    "    for (gl, han_char, bases, f_name) in zip(g_data, han_chars, base_data, f_names):\n",
    "        g, l = gl\n",
    "        original_score = exhaustScore(ref_char, f_name, data_dir, force_refresh=True, save=False)\n",
    "        exhaustive_scores.append(original_score)\n",
    "    return exhaustive_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf7e9d-44e0-4adb-99cc-94b240d5b447",
   "metadata": {},
   "source": [
    "## Loading genes from the directory and storing scores\n",
    "This will compare all of the genes in \"Genes/sixgenes/test\" with all of the archetypes in \"Reference/6-stroke_characters\"\n",
    "\n",
    "all_scores is a 2-d list that holds all of the score numbers. Unfortunately, each han character is a row instead of a column\n",
    "\n",
    "ref_chars holds all of the han character gene names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39482b-0a6e-4f17-b055-a5c5b7c4a851",
   "metadata": {},
   "source": [
    "### Note about loadRef2!\n",
    "Holiday's original code didn't include loadRef2! I made it. It's the exact same as loadRef, except the ref_path doesn't include the {han_char[0]}000 part of it. I did this so I wouldn't have to make all of those files in my test folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ef2a6-5103-40f2-bff4-292367203660",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "data_dir = \"Genes/sevengenes/maint_0.05 on 4F4D.01\"\n",
    "ref_dir = \"Reference/7-stroke_characters\"\n",
    "ref_chars = os.listdir(ref_dir)\n",
    "for char in ref_chars:\n",
    "    han_char = char[:4:]\n",
    "    ref_g, ref_l, output_size = loadRef2(han_char, ref_dir)\n",
    "    char_data = loadGeometryBases(data_dir, output_size)\n",
    "    f_names = []\n",
    "    f_names = os.listdir(data_dir)\n",
    "    f_names.sort()\n",
    "    exhaustive_scores = exhaustiveScores(han_char, char_data, data_dir)\n",
    "    all_scores.append(exhaustive_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af13412-466c-4cf4-8200-c7bb6492649a",
   "metadata": {},
   "source": [
    "## Generating a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aacabb-c995-4e24-8aa7-0e0ee5c63f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_dir = \"GenXml\"\n",
    "gene_names = []\n",
    "#gene_names = [f_name.split(\".\")[0] for (i, f_name) in enumerate(f_names)]\n",
    "for name in f_names:\n",
    "    x = len(name) - 5\n",
    "    gene_names.append(name[:x])\n",
    "all_scores_t = np.array(all_scores).T\n",
    "#below code makes a label for which gene is which\n",
    "genes = pd.Series(f_names, name=\"Genes\")\n",
    "frame = {}\n",
    "frame = pd.DataFrame.from_records(all_scores_t, columns=ref_chars)\n",
    "#this allows the label for the genes to be added to the data frame\n",
    "result = pd.concat([genes, frame], axis=1)\n",
    "table = pd.DataFrame(result)\n",
    "table.to_csv('ExhaustiveTable.csv', index = \"false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475a1b5-0da3-48b0-a11a-63280f7ce316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
